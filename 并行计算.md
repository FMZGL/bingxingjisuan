# 一、并行计算机的体系结构

### 1. PVP（Parallel Vector Processor，并行向量处理机）

- **核心特点**：由少数几个（通常 1-8 个）高性能向量处理器组成，共享一个大容量内存和 I/O 系统，通过高带宽总线连接。
- **通俗理解**：像几个 “超级计算器” 共用一个大仓库（内存），每个计算器擅长处理成组的数字（向量），比如同时计算 1000 对数字的加减。
- **典型场景**：早期超级计算机（如 Cray 系列），适合处理气象模拟、流体力学等需要大量向量运算的任务。
- **缺点**：成本高，扩展性差（很难超过 8 个处理器）。

### 2. SMP（Symmetric Multi-Processor，对称多处理器）

- **核心特点**：多个相同的处理器（如 4 核、8 核 CPU）通过共享总线连接到**同一块内存**，所有处理器地位平等（对称），都能直接访问内存和 I/O 设备。
- **通俗理解**：一群能力相同的人围坐在一张大桌子旁，桌上的文件（数据）大家都能看、能改，谁要用水笔（I/O 设备）直接拿就行，没有 “领导” 和 “下属” 之分。
- **我们最熟悉的模型**：日常用的多核电脑（如笔记本、台式机）都是 SMP 结构 ——4 核 CPU 就是 4 个处理器共享同一块内存。
- **优点**：编程简单（不用考虑数据分配），通信快（直接读内存）。
- **缺点**：处理器数量有限（一般不超过 64 个），否则总线会成为瓶颈（大家抢着用总线，反而变慢）。

### 3. MPP（Massively Parallel Processor，大规模并行处理机）

- **核心特点**：由成百上千个独立节点（每个节点是一个处理器 + 自己的私有内存）组成，节点之间通过高速网络（如 InfiniBand）连接，**没有共享内存**。
- **通俗理解**：成千上万的人分散在不同房间，每人有自己的笔记本（私有内存），要交换数据只能靠打电话（网络通信），谁也不能直接看别人的笔记本。
- **典型场景**：顶级超级计算机（如 “天河一号”“神威・太湖之光”），适合处理超大规模任务（如全球气候模拟、基因测序）。
- **优点**：扩展性极强（能轻松做到几万甚至几十万处理器），总计算能力惊人。
- **缺点**：编程复杂（需要明确数据如何在节点间传递），通信延迟比 SMP 高。

### 4. DSM（Distributed Shared Memory，分布式共享内存）

- **核心特点**：物理上是多个节点各有私有内存（类似 MPP），但通过软件或硬件模拟出 “共享内存” 的效果 —— 每个节点可以 “假装” 直接访问其他节点的内存，不用显式发消息。
- **通俗理解**：还是分散在不同房间的人，每人有自己的笔记本，但通过一个 “云同步” 工具，让大家觉得在编辑同一个文档（实际是后台自动同步），不用每次手动传文件。
- **优点**：兼顾 MPP 的扩展性和 SMP 的编程简单性（程序员不用手动管理数据传输）。
- **缺点**：同步和一致性维护复杂，“假装共享” 的背后有额外开销（比如网络传输延迟）。

### 5. COW（Cluster of Workstations，工作站集群）

- **核心特点**：用普通 PC 或工作站（比如几十台台式机）通过以太网连接成集群，节点之间地位平等，通常通过软件（如 MPI、Hadoop）实现协作。
- **通俗理解**：把办公室里的几十台普通电脑用网线连起来，安装一套 “协作软件”，让它们合力完成一个大任务（比如同时渲染一部电影的不同镜头）。
- **优点**：成本极低（用现成设备），灵活（随时加机器或减机器）。
- **缺点**：性能不如专用 MPP（普通网络速度慢），适合预算有限的场景（如高校科研、中小企业数据处理）。

### 一句话总结区别

- **SMP**：少数处理器共享内存（“同桌协作”）
- **MPP**：海量处理器各有内存，靠网络通信（“异地大军”）
- **DSM**：物理分散，假装共享内存（“异地协作但像同桌”）
- **PVP**：专用向量处理器，适合特定运算（“专业团队”）
- **COW**：普通电脑凑成的集群（“平民军团”）







# 二、并行计算机访存模式

要理解并行计算机的 “访存模型”，可以先抓住核心：它本质是 “多个计算单元（比如 CPU 核心、节点）怎么去拿数据” 的规则。就像一群人去仓库取货，不同的访存模型，就是不同的 “取货流程”—— 有的直接拿，有的要登记，有的得按顺序拿。下面用 “仓库取货” 的生活场景，拆解 4 种最核心的访存模型，保证一听就懂：

### 1. UMA（均匀存储访问模型）：“所有人到同一个仓库取货，速度一样”

#### 核心逻辑：

所有计算单元（比如 CPU 核心）共享**同一块内存**（相当于 “一个公共仓库”），而且不管哪个计算单元去拿数据，从内存读 / 写的速度都一样（“均匀” 就是这个意思）。

#### 生活类比：

公司所有人都去同一个中央仓库取文件，仓库只有一个出入口，不管是老板、员工，从门口走到货架拿文件的时间都一样，没有 “特殊通道”。

#### 关键特点：

- **优点**：规则简单 —— 不用管 “该去哪个仓库”，所有人盯准一个地方就行，编程也容易（不用考虑不同内存的速度差异）。
- **缺点**：“仓库门口会堵车”—— 如果计算单元太多（比如几十上百个核心），大家都挤着去同一个内存拿数据，会出现 “内存访问冲突”，反而变慢（相当于仓库门口排队）。

#### 常见场景：

我们日常用的多核电脑（比如 4 核、8 核 CPU）就是 UMA—— 所有核心共享同一条内存条，访问速度没有差别；早期的小型并行机也多是这种模型。

### 2. NUMA（非均匀存储访问模型）：“每人有自己的小仓库，也能去别人的小仓库，速度不一样”

#### 核心逻辑：

把内存拆成好几块，每个 “计算单元组”（比如 2 个 CPU 核心算一组）配一块 “本地内存”（相当于 “个人小仓库”）；同时，所有计算单元也能访问其他组的 “远程内存”（别人的小仓库）。但关键是：访问自己的本地内存很快，访问远程内存很慢（“非均匀” 就是速度不一样）。

#### 生活类比：

公司按部门分了小仓库 —— 销售部有销售仓库，技术部有技术仓库。销售拿自己仓库的文件只要 1 分钟，但要拿技术仓库的文件，得先联系技术部登记，再跑过去，要 5 分钟。

#### 关键特点：

- **优点**：“减少堵车”—— 大部分时候，计算单元只拿自己本地内存的数据，不用挤公共仓库；而且内存总容量大（多个小仓库加起来），能支持更多计算单元。
- **缺点**：“得记清仓库位置”—— 编程时要尽量让计算单元用自己的本地内存（不然远程访问太慢，拖慢整体速度），相当于 “取货前先想清楚：自己仓库有没有，没有再去别人那”。

#### 常见场景：

中大型服务器（比如用于数据库、云计算的 2 路 / 4 路 CPU 服务器）—— 比如 2 个 CPU 芯片，每个 CPU 带自己的内存条（本地内存），但两个 CPU 也能互相访问对方的内存条（远程内存）。

### 3. NORMA（非远程存储访问模型）：“每人只有自己的小仓库，不能去别人的，要数据只能让别人送过来”

#### 核心逻辑：

每个计算单元都有**完全属于自己的私有内存**（自己的小仓库），而且不能直接去访问其他计算单元的内存 —— 如果需要别人的数据，必须通过 “网络发消息”（比如 “请把你的数据传我一份”），让对方把数据 “送过来”，自己不能主动去拿。

#### 生活类比：

异地办公的团队，每人家里只有自己的文件柜（私有内存）。北京的同事要上海同事的文件，不能直接去上海开文件柜，只能发消息让上海同事把文件拍照发过来。

#### 关键特点：

- **优点**：“绝对不堵车”—— 每个计算单元的内存只有自己用，不会有冲突；而且可以无限加计算单元（只要网络能连），扩展性极强（相当于可以加无数个异地同事，每人一个文件柜）。
- **缺点**：“取货效率低”—— 要拿别人的数据，得等对方传过来，尤其是数据量大时（比如传一个 1G 的文件），会花很多时间（相当于等快递）；编程也麻烦（得明确 “谁要什么数据”“什么时候传”）。

#### 常见场景：

大规模并行机、超级计算机（比如 “天河”“神威”）、大数据集群（比如多台服务器跑 Spark 任务）—— 每台服务器就是一个计算单元，有自己的内存，靠高速网络互相传数据。

### 4. CC-NUMA（高速缓存一致性非均匀存储访问模型）：“每人有小仓库 + 随身抽屉，抽屉里的东西要保持一致”

#### 核心逻辑：

在 NUMA 的基础上，给每个计算单元加了 “高速缓存”（相当于 “随身抽屉”）—— 计算单元常用的数据会存在抽屉里，拿起来更快；同时，通过特殊规则保证：**所有计算单元的 “抽屉” 里，同一份数据的内容是一样的**（比如 A 的抽屉里有 “文件 X”，B 的抽屉里也有 “文件 X”，如果 A 改了自己抽屉里的 X，B 的抽屉里的 X 会自动同步更新，不会出现 “A 改了 X，B 还拿着旧 X” 的情况，这就是 “高速缓存一致性”）。

#### 生活类比：

还是部门分小仓库，每个人除了能去部门仓库，还随身带个抽屉（高速缓存），常用的文件放抽屉里。公司有个规则：如果 A 改了自己抽屉里的 “客户名单”，会立刻通知所有人 “客户名单更新了”，大家抽屉里的旧名单会自动换成新的，保证所有人手里的名单都一样。

#### 关键特点：

- **优点**：“又快又准”—— 随身抽屉（高速缓存）让常用数据访问更快，小仓库（本地内存）减少冲突，还能保证数据一致（不会用错旧数据）。
- **缺点**：“规则复杂”—— 要维护所有抽屉的数据一致，需要额外的硬件 / 软件逻辑（相当于公司要专门安排人负责 “同步名单”），成本更高。

#### 常见场景：

高端服务器、高性能计算节点（比如用于 AI 训练、科学计算的服务器）—— 比如 4 个 CPU 组成的节点，每个 CPU 带本地内存和高速缓存，同时通过 “缓存一致性协议”（比如 Intel 的 QPI 协议）保证缓存数据一致。

# 2.1.2、静态互连网络

假设并行计算机是一个 “大办公室”，里面的每台 “小电脑”（专业叫 “处理单元 / PE”）就是一个 “员工”。员工之间要传递文件（数据）才能协同干活，而 “静态互联网络” 就是办公室里**固定不变的 “传文件通道”**—— 比如预先铺好的专线、固定的桌面传递路线，一旦建好就不能随便改，员工只能沿着这些通道传东西，不能临时加新通道或改路线。

简单说，它的核心就是 “**通道固定，不能动态调整**”，所有处理单元之间的连接关系是提前设计好的（比如用硬件电路焊死），工作时不会变。

### 1. 一维线性阵列（Linear Array）

- **结构**：所有节点按直线排列，每个中间节点仅连接左右相邻节点，两端节点只连接一个邻居（如 1-2-3-…-N）。
- **节点度**：两端节点度为 1，中间节点度为 2，平均节点度≈2。
- **网络直径**：N 个节点时，直径为 N-1（如 1 到 N 需经过 N-1 步）。
- **对剖宽度**：1（从任意位置切开直线，只需切断 1 条边）。

**特点**：结构最简单，成本极低，但直径随节点数线性增长，通信效率差，适合小规模、数据按顺序处理的场景（如流水线计算）。

### 2. 二维网孔（2D Mesh）

- **结构**：节点排列成 M×N 的网格，每个内部节点连接上下左右 4 个邻居，边缘节点连接 2-3 个邻居（若边缘不相连则为 “非环绕网孔”；若每行首尾、每列首尾相连则为 “环面网孔（Torus）”）。
- **节点度**：非环绕网孔中，内部节点度为 4，边缘节点度为 2-3，平均节点度≈4；环面网孔中所有节点度均为 4。
- 网络直径
  - 非环绕网孔（√N×√N 规模）：直径≈2√N（对角线节点需横向 + 纵向各√N 步）。
  - 环面网孔：直径≈√N（可双向绕路，缩短一半距离）。
- 对剖宽度
  - 非环绕网孔：√N（沿中线切开，需切断√N 条边）。
  - 环面网孔：√N（同样沿中线切开，但因环绕连接，对剖宽度不变）。

**特点**：节点度固定（4），直径随节点数平方根增长，平衡性好，是大型并行机常用结构（如天河超级计算机）。

### 3. 树（Tree）

- **结构**：以根节点为顶端，每层节点连接下一层节点，形成分层分支结构（如二叉树：根节点连接 2 个子节点，每个子节点再连接 2 个孙节点，直到叶节点）。
- **节点度**：根节点和内部节点度为 k（k 叉树，通常 k=2），叶节点度为 1，平均节点度≈2。
- **网络直径**：N 个节点的二叉树，直径≈2log₂N（从最左叶节点到最右叶节点需经过根节点，路径长度为 2× 层数）。
- **对剖宽度**：1（切断根节点与下一层的连接，即可将树分为两部分）。

**特点**：直径较小（对数增长），但对剖宽度极小（瓶颈在根节点），导致数据传输带宽受限，适合层级化控制场景，不适合大规模数据并行。

### 4. 超立方（Hypercube）

- **结构**：n 维超立方由 2ⁿ个节点组成，每个节点用 n 位二进制编号，编号仅差 1 位的节点直接相连（如 3 维超立方：000 与 001、010、100 相连，共 8 个节点）。
- **节点度**：n（n 维超立方中每个节点连接 n 个邻居）。
- **网络直径**：n（任意两节点的二进制编号差 k 位，最短路径为 k 步，最大值为 n）。
- **对剖宽度**：2ⁿ⁻¹（将节点按最高位 0/1 分为两组，每组 2ⁿ⁻¹ 个节点，需切断 2ⁿ⁻¹ 条边）。

**特点**：节点度、直径均随节点数对数增长（因 N=2ⁿ，n=log₂N），对剖宽度大（接近 N/2），通信效率极高，适合大规模并行计算，但结构复杂，扩展时需按 2ⁿ倍增加节点。

### 5. 嵌入（Embedding）

- **说明**：嵌入不是独立拓扑，而是指将一种网络结构 “映射” 到另一种网络中（如将树结构嵌入到超立方中），使原网络的节点和连接关系在目标网络中保持等效。

- 指标分析

  ：嵌入的性能取决于目标网络和映射方式，例如：

  - 将树嵌入超立方：节点度由树的 k 变为超立方的 n，直径可能因映射优化而小于原树，对剖宽度取决于超立方的特性。
  - 若嵌入不合理（如将超立方嵌入线性阵列），可能导致直径大幅增加（失去原网络优势）。

**作用**：解决不同拓扑网络的兼容问题，使算法能在不同架构的并行机上运行。



# 2.1.3 动态互连网络

动态互联网络和静态互联网络的核心区别在于：**连接关系可以灵活变化**。就像现实中的交通系统，静态网络是 “固定轨道”（比如火车只能沿铁轨跑），而动态网络是 “有调度员的公路网”—— 可以根据实时需求（比如哪条路堵了）临时改变数据的传输路线。

动态网络里有 “中间调度设备”（类似交通信号灯或调度中心），能根据数据的目的地，实时选择最优路径，不用像静态网络那样只能走固定路线。下面用生活化的例子介绍三种最常见的动态网络：

### 1. 总线（Bus）：就像 “办公室里的一条公共电话线”

- **结构**：所有处理单元（比如 10 台电脑）都连到同一条 “总线”（可以理解为一根共享的数据线）上，就像多个工位共用一条电话线。
- **工作方式**：某台电脑要发数据时，先 “抢总线”（类似打电话前先拿起听筒听有没有占线），抢到后才能发，其他电脑只能等着。数据发出去后，所有电脑都会收到，但只有目标电脑会 “接电话”， others 自动忽略。
- **优点**：结构超简单（一条线连所有设备），成本极低，适合设备少的场景（比如早期的家用电脑扩展槽）。
- **缺点**：“一拥而上” 会堵车 —— 设备越多，抢总线的冲突越频繁，速度越慢。就像 100 个人抢用一条电话线，大部分时间都在等。

### 2. 交叉开关（Crossbar Switch）：像 “全互通的十字路口”

- **结构**：假设有 N 个发送端和 N 个接收端，中间有一个 “交叉开关矩阵”—— 每个发送端和每个接收端之间都有一个独立的 “开关”（类似十字路口的每个方向都有单独的红绿灯）。比如 4 台发送机和 4 台接收机，就有 4×4=16 个开关。
- **工作方式**：发送数据时，直接打开对应路径的开关。比如 “发送机 1→接收机 3”，就把它们之间的开关打开，其他路径互不干扰。多个不同路径可以同时传输（只要不冲突），比如同时打开 “1→3” 和 “2→4” 的开关。
- **优点**：速度极快，没有冲突（只要路径不重复），就像每个方向的车都有专属车道，互不影响。
- **缺点**：成本太高 —— 开关数量是 N²，当设备多到 100 个时，就需要 10000 个开关，硬件复杂度爆炸，只适合小规模场景（比如高端服务器内部）。

### 3. 多级互联网络（Multistage Interconnection Network）：像 “多层换乘的地铁网”

- **结构**：把多个 “小交叉开关” 按层级连接起来，形成多级结构。比如最经典的 “Omega 网络”，有 3 级开关，每级有 4 个小开关，整体能连接 8 个发送端和 8 个接收端（类似地铁 1 号线→换乘 2 号线→换乘 3 号线到达目的地）。
- **工作方式**：数据从发送端出发，经过多级开关 “换乘”，最终到达接收端。比如 “发送端 5→接收端 3”，可能先经过第 1 级开关 A，再经第 2 级开关 B，最后经第 3 级开关 C 到达，路径可以动态选择。
- **优点**：平衡了成本和性能 —— 开关数量是 N×logN（比交叉开关的 N² 少得多），但能支持较多设备（比如几百到几千个节点），而且可以同时传输多条不冲突的路径。
- **缺点**：结构比总线复杂，可能出现 “路径冲突”（比如两条数据想走同一段线路），需要调度算法解决。

# 2.2.1 选路方法

并行计算机的 “选路方法”，简单说就是**数据在不同处理单元（节点）之间传输时，如何选择路径的规则**。就像快递员送包裹需要规划路线（走哪条街、怎么转弯），数据从 “起点节点” 到 “终点节点” 也需要一套固定规则来确定路径，避免混乱或冲突。

选路方法的核心是解决两个问题：① 怎么找到从起点到终点的路径；② 怎么避免不同数据在传输时 “撞车”（比如同时争抢同一条线路）。下面介绍两种经典的选路方法：

### 1. X-Y 选路法：“先横后竖” 的网格导航

X-Y 选路法专门用于**二维网孔（或环面网孔）结构**的并行计算机（节点排列成网格，类似棋盘坐标），规则像城市导航里的 “先沿 X 轴走，再沿 Y 轴走”。

#### 举个例子：

假设节点按网格坐标编号，比如起点是 (2,1)，终点是 (5,4)（前一个数是 X 坐标，后一个是 Y 坐标）：

- **第一步（X 方向）**：先沿水平方向（X 轴）移动，从 X=2 走到 X=5（不管 Y 坐标），比如路径是 (2,1)→(3,1)→(4,1)→(5,1)；
- **第二步（Y 方向）**：再沿垂直方向（Y 轴）移动，从 Y=1 走到 Y=4（X 坐标固定为 5），路径是 (5,1)→(5,2)→(5,3)→(5,4)。

#### 特点：

- **规则简单**：就像 “先横着走到目标列，再竖着走到目标行”，不会走回头路；
- **避免冲突**：因为所有数据都按 “先 X 后 Y” 的顺序走，方向统一，不容易在路口 “撞车”；
- **适用场景**：所有二维网孔结构的并行机（比如很多超级计算机用的 Torus 结构），是网格网络中最常用的选路法。

### 2. E - 立方选路法：“按位翻牌” 的超立方导航

E - 立方选路法专门用于**超立方结构**的并行计算机（节点按二进制编号，比如 3 维超立方的节点编号是 000、001、010…111），规则类似 “按二进制位一步步修正”。

#### 举个例子：

3 维超立方中，起点是 001（二进制），终点是 110：

- 先看二进制的最高位（第 3 位）：起点是 0，终点是 1→不匹配，所以先把这一位 “翻成 1”，路径 001→101；
- 再看中间位（第 2 位）：当前是 0，终点是 1→不匹配，翻成 1，路径 101→111；
- 最后看最低位（第 1 位）：当前是 1，终点是 0→不匹配，翻成 0，路径 111→110。

每一步只改一个二进制位，最终从起点 “翻” 到终点。

#### 特点：

- **按位导航**：像玩 “翻牌游戏”，每次只修正一个二进制位，保证每步都向终点靠近；
- **路径唯一**：只要按 “从高位到低位”（或固定顺序）翻位，从起点到终点的路径是唯一的，避免迷路；
- **适用场景**：所有超立方结构的并行机，充分利用超立方 “节点间距离短” 的优势（n 维超立方最多只需 n 步）。



# 2.2.2 开关技术

在并行计算机的互联网络中，“开关技术” 指的是**数据在节点或交换机之间传输时，如何处理、转发消息的规则和方式**。就像快递站处理包裹的流程（比如怎么打包、怎么分拣、怎么传递），开关技术决定了数据 “消息” 在网络中如何被处理和转发，核心是提高传输效率、减少延迟。

下面用 “快递运输” 的例子，通俗解释开关技术中的三个关键概念：

### 1. 消息格式：数据的 “打包方式”

消息格式就是**规定数据在传输时的 “包装结构”**，就像快递包裹必须有 “面单（收件人信息）+ 货物（实际内容）” 一样，网络中的消息也需要固定格式，让接收方知道如何处理。

通常包含三部分：

- **头部（Header）**：相当于快递面单，记录关键信息 —— 比如消息要发到哪个节点（目的地地址）、消息长度、优先级等，是交换机或节点判断 “怎么转发” 的依据。
- **数据体（Data）**：相当于包裹里的货物，是真正要传输的内容（比如计算数据、指令等）。
- **尾部（Trailer）**：相当于快递单的备注，可能包含校验信息（比如检查数据是否传输中出错）、消息结束标记等。

**作用**：统一格式让所有节点和交换机 “看得懂” 消息，知道该往哪发、怎么处理，避免混乱。

### 2. 存储转发（Store-and-Forward，SF）选路：“先存全，再转发”

存储转发是最经典的消息转发方式，规则类似 **“快递站必须收到完整包裹后，才会继续往下一站发”**。

#### 过程：

- 消息从起点出发，到达第一个交换机（或中间节点）时，交换机先把**整个消息**（包括头部、数据体、尾部）完整接收并存储起来；
- 确认收到完整消息后，交换机根据消息头部的目的地信息，决定下一站该发往哪里；
- 再把整个消息转发到下一个交换机，重复这个过程，直到到达终点。

#### 例子：

就像你寄一个大包裹到外地：

- 本地快递点必须先收到你的完整包裹（拆开检查、扫码存档），才会装上运往省会的车；
- 省会快递点收到完整包裹后，再转发到目的地城市的快递点，最后送到收件人手里。

#### 特点：

- 优点：安全可靠，中间节点能检查消息是否完整、有没有错误，错了可以要求重发；
- 缺点：延迟高，必须等整个消息都到了才能转发，尤其对大消息来说，等待时间长。

### 3. 切通（Cut-Through，CT）选路：“边收边发，不等全到”

切通选路是为了减少延迟设计的，规则类似 **“快递站只要看到面单，就先把包裹往目的地方向发，不用等整个包裹收完”**。

#### 过程：

- 消息从起点出发，先传输 “头部” 到第一个交换机；
- 交换机收到头部后，立刻解析出目的地信息，确定下一站路径；
- 不等后面的数据体和尾部完全到达，就开始把已经收到的部分（包括头部和陆续到达的数据体）转发到下一个交换机；
- 整个过程中，消息像 “流水” 一样在网络中传递，前一段还在传输，后一段已经开始转发。

#### 例子：

类似你用即时通讯发一段长文字：

- 你刚打完前半句 “我明天要...”，消息就已经开始往服务器传了；
- 服务器收到前半句，不等你打完后半句，就先转发给接收方，实现 “边发边传”。

#### 特点：

- 优点：延迟低，尤其对长消息来说，比存储转发快很多（不用等完整接收）；
- 缺点：如果中间发现路径堵塞或错误，已经发出去的部分可能白费，需要重新传输，可靠性略低于存储转发。



# 2.3 单一信包一到一传输

“单一信包一到一传输” 是并行计算机网络中最基础的一种数据传输方式，可以拆成三个关键词来理解：

- **“单一信包”**：指数据被打包成一个完整的 “信息包”（类似一个快递包裹），而不是分成多个小包传输。
- **“一到一”**：指数据传输的关系是 “一个发送节点” 到 “一个接收节点”，就像 “一对一” 寄快递，不是 “一个寄给多个”（一对多），也不是 “多个寄给一个”（多对一）。
- **“传输”**：就是这个信包从发送节点通过网络传到接收节点的过程。

举个生活例子：就像你给朋友寄一个完整的包裹，包裹没被拆开（单一信包），而且是你一个人寄给这一个朋友（一到一），快递小哥把包裹从你家送到朋友家（传输）。

这种方式的特点是：

- 简单直接，不需要复杂的拆分或分发逻辑；

- 是并行计算机中最基本的通信方式，其他复杂传输（比如一对多、多对多）往往都是基于它组合实现的；

- 适合传输少量数据或独立的指令，比如两个处理单元之间交换计算结果。

  

# 2.4.1 使用SF进行一到多播送

在环、环绕网孔和超立方等静态互连网络中，使用**存储转发（SF）技术**实现 “一到多传输”（一个源节点向多个目标节点发送数据），核心思路是：源节点将数据打包成消息，通过存储转发机制，按特定规则依次或并行地将消息传递到各个目标节点。具体网络的拓扑结构不同，具体路径选择和转发策略也不同，下面分别说明：

### 1. 环（Ring）网络上的 SF 一到多传输

**环网络特点**：节点连成闭合回路，每个节点只与左右两个邻居直接相连（如 0-1-2-3-0）。

**SF 一到多传输过程**：
假设源节点是 0，要向节点 2、3 发送数据：

- 源节点 0 先将数据打包成消息，消息头部包含所有目标节点地址（或按顺序标记下一个目标）。
- **第一步**：0 将消息发送给左邻居 1（或右邻居 3，根据最近路径选择）。节点 1 采用 SF 方式，先完整接收消息并存储，解析头部后发现需要继续转发。
- **第二步**：若目标包括 3，节点 1 将消息转发给 2；节点 2 接收并存储后，若自身是目标则留下数据，再转发给 3；节点 3 接收后，若自身是目标则留下数据，继续转发（因环是闭合的，需设置 “终止条件” 避免消息无限循环，比如标记已访问节点）。
- **优化策略**：采用 “令牌传递” 或 “广播令牌”，源节点发送的消息附带 “可复制标记”，每个中间节点收到后，若自身是目标则复制数据，再按环方向转发给下一个节点，直到所有目标都收到。

**特点**：消息沿环单向或双向流动，靠中间节点存储转发和复制实现多目标传输，延迟随环长度和目标数量增加而增加。

### 2. 环绕网孔（Torus，二维环面）上的 SF 一到多传输

**环绕网孔特点**：节点排列成二维网格，且每行 / 列首尾相连（如 3×3 环面中，(0,2) 右邻居是 (0,0)，(2,1) 下邻居是 (0,1)），每个节点有 4 个邻居（上下左右）。

**SF 一到多传输过程**：
假设源节点是 (0,0)，要向 (1,2)、(2,1) 发送数据：

- 源节点 (0,0) 将数据打包，消息头部包含所有目标坐标，采用 X-Y 选路的扩展策略（先按 X 方向转发，再按 Y 方向，因是环绕结构可双向选路）。
- 向 (1,2) 传输
  - (0,0)→(1,0)（X 方向 + 1），节点 (1,0) 完整接收消息（SF 机制），解析到目标 (1,2) 需 Y 方向 + 2，转发给 (1,1)；
  - (1,1) 接收存储后，转发给 (1,2)，目标节点接收并存储数据。
- 向 (2,1) 传输
  - 源节点 (0,0) 可并行发送另一份消息（或同一消息标记多个目标），经 Y 方向 + 1 到 (0,1)，节点 (0,1) 存储后，沿 X 方向 + 2（因环绕，X=0→2 只需 + 2 步）转发到 (2,1)，目标节点接收。

**特点**：利用二维环绕结构的多路径特性，可并行向不同区域的目标转发消息，中间节点通过解析头部坐标决定转发方向，SF 机制保证消息完整后再传递，可靠性高。

### 3. 超立方（Hypercube）网络上的 SF 一到多传输

**超立方特点**：n 维超立方有 2ⁿ个节点，每个节点用 n 位二进制编号，仅相差 1 位的节点直接相连（如 3 维超立方中，001 与 000、011、101 相连）。

**SF 一到多传输过程**：
假设 3 维超立方中，源节点是 000，要向 010、101 发送数据：

- 源节点 000 将数据打包，消息头部包含目标节点的二进制编号，采用 E - 立方选路的扩展策略（按位修正，支持多目标标记）。
- 向 010 传输
  - 000 与 010 的二进制差异在第 2 位（从左数），000 先将消息转发给 010（直接相连），目标节点完整接收（SF 机制）后存储数据。
- 向 101 传输
  - 000 与 101 的差异在第 1 位和第 3 位，000 先转发给 100（修正第 1 位），节点 100 完整接收消息后，解析到还需修正第 3 位，转发给 101，目标节点接收存储。

**优化策略**：若目标节点较多，可利用超立方的 “广播特性”—— 源节点先将消息发给所有直接相连的邻居（如 000 发给 001、010、100），每个邻居接收后（SF 机制），再转发给各自的邻居（排除源节点），以此类推，实现消息在超立方中 “扩散式” 传播，直到所有目标节点收到。

**特点**：超立方节点间距离短（最多 n 步），SF 转发时中间节点只需处理 1 位差异，效率高，适合快速向多个分散目标传输数据。



# 2.4.2使用CT进行一到多播送

在环、网孔和超立方网络中，使用**切通（CT）技术**实现 “一到多传输”（一个源节点向多个目标节点发送数据），核心思路是：源节点无需等待整个消息完全生成，只要确定头部信息（包含目标地址），就可立即开始传输，中间节点收到头部后也会边接收消息边转发，大幅降低延迟。具体实现因网络拓扑不同而有所差异，下面分别说明：

### 1. 环（Ring）网络上的 CT 一到多传输

**环网络特点**：节点连成闭合回路，每个节点只与左右邻居相连（如 0-1-2-3-0），数据只能沿环单向或双向流动。

**CT 一到多传输过程**：
假设源节点 0 要向节点 2、3 发送数据：

- 源节点 0 生成消息头部（包含目标节点 2、3 的标识），无需等待完整数据体生成，就立即将头部发送给右邻居 1（CT 的 “边生成边传” 特性）。
- 节点 1 收到头部后，不等完整消息到达，立即解析出目标包含 2、3，判断需要继续向右转发，于是边接收后续数据体，边将已收到的部分转发给节点 2。
- 节点 2 收到头部和部分数据后，发现自身是目标之一，立即复制已收到的数据（同时继续接收剩余部分），并继续向右转发给节点 3。
- 节点 3 收到后，同样复制数据（自身是目标），并继续转发（为避免消息在环中无限循环，头部会包含 “生命周期” 标记，每经过一个节点减 1，减到 0 则停止转发）。

**特点**：消息像 “流水” 一样沿环流动，中间节点 “边收边传”，比存储转发（SF）延迟更低；但如果某个目标节点后面还有其他目标，必须按顺序传递，无法跳步。

### 2. 网孔（Mesh）网络上的 CT 一到多传输

**网孔特点**：节点按二维网格排列（如 3×3 网孔：(0,0)-(0,1)-(0,2)；(1,0)-(1,1)-(1,2) 等），每个节点连接上下左右邻居（边缘节点连接较少），常用 X-Y 选路规则（先沿 X 轴、再沿 Y 轴传输）。

**CT 一到多传输过程**：
假设源节点 (0,0) 要向 (1,2)、(2,1) 发送数据：

- 源节点 (0,0) 生成消息头部（包含两个目标的坐标），立即启动传输。因目标在不同区域，采用 “分支转发” 策略：
  - 向 (1,2) 传输：按 X-Y 规则，先沿 X 轴发送头部到 (1,0)。节点 (1,0) 收到头部后，不等完整消息，立即判断需沿 Y 轴继续转发，边接收数据边传给 (1,1)，最终到达 (1,2)。
  - 向 (2,1) 传输：源节点同时（或稍晚）生成另一个头部（或同一头部标记多目标），先沿 Y 轴发送到 (0,1)。节点 (0,1) 收到头部后，判断需沿 X 轴转发到 (2,1)，边接收边传给 (1,1)，再到 (2,1)。
- 中间节点（如 (1,1)）若同时收到两个方向的消息，会通过 CT 的 “通道分离” 机制，分别处理不同目标的转发，避免冲突。

**特点**：利用网孔的二维路径特性，可向不同区域的目标 “并行分支” 转发，CT 的 “边收边传” 特性让每个分支的延迟都比 SF 低，适合多目标分散在不同行 / 列的场景。

### 3. 超立方（Hypercube）网络上的 CT 一到多传输

**超立方特点**：n 维超立方有 2ⁿ个节点，节点用 n 位二进制编号（如 3 维：000、001、010...111），编号仅差 1 位的节点直接相连，路径短（最多 n 步）。

**CT 一到多传输过程**：
假设 3 维超立方中，源节点 000 要向 010、101 发送数据：

- 源节点 000 生成消息头部（包含目标的二进制编号），无需等待完整数据，立即根据目标差异位转发：
  - 向 010 传输：000 与 010 仅第 2 位不同（0→1），直接将头部发送给相邻节点 010。010 收到头部后，发现自身是目标，立即开始接收并复制数据（同时无需继续转发）。
  - 向 101 传输：000 与 101 第 1 位（0→1）和第 3 位（0→1）不同，先将头部发送给第 1 位不同的相邻节点 100。100 收到头部后，不等完整消息，立即解析出还需修正第 3 位，边接收数据边转发给 101（100 与 101 仅第 3 位不同），101 收到后复制数据。
- 若目标更多（如向 001、011、101、111 发送），源节点 000 会先向所有直接相连的邻居（001、010、100）发送头部，每个邻居收到后，再根据自身与其他目标的差异位继续转发，形成 “扩散式” CT 传输（边收边传，快速覆盖所有目标）。

**特点**：超立方的 “短路径 + 多邻居” 特性与 CT 的 “低延迟” 完美匹配，多目标传输时能通过二进制位差异快速分支，延迟远低于环和网孔，是三种网络中 CT 效率最高的场景。



# 2.5.1 使用SF进行多到多播送

咱们用 “小区快递站送货” 的生活场景，把 “存储转发（SF）在三种网络上的多到多传输” 讲明白 ——“多到多” 就是**多个快递站（源节点）同时给多个住户（目标节点）送包裹**，“存储转发” 就是每个快递站 / 中转站必须 “先把包裹完整收下，再往下一站送”，不能只看个面单就转。

### 1. 环网络：小区里的 “环形快递路线”

#### 场景类比：

小区的快递路线是个圈（比如 1 号楼→2 号楼→3 号楼→4 号楼→1 号楼），每个楼只有 “左右两个邻居楼” 能直接送快递，没有其他小路。现在有两个快递站要送货：

- 快递站 A（1 号楼）要给 3 号楼送包裹；
- 快递站 B（2 号楼）要给 4 号楼送包裹。

#### SF 多到多传输过程：

1. **快递站 A 送货**：
   先把包裹完整交给 2 号楼（左邻居），2 号楼的快递点必须 “把包裹全收下、扫码确认没问题”（这就是存储转发的 “存”），再按环形路线交给 3 号楼（这就是 “转发”），3 号楼收下就完成了。
2. **快递站 B 送货**：
   同时把包裹交给 3 号楼（右邻居），3 号楼同样 “先收全、确认好”，再转发给 4 号楼，4 号楼收下完成。

#### 遇到 “堵车” 怎么办？

如果快递站 A 要给 4 号楼送，快递站 D 要给 2 号楼送，两条路线会在 3 号楼 “碰面”。这时 3 号楼的快递点会先收下 A 的包裹，转发完再收 D 的包裹 —— 按 “先到先处理” 的顺序排队，保证包裹不丢。

#### 特点：

路线固定像绕圈，简单但慢，要是小区（节点）多了，包裹要绕好多圈才能到。

### 2. 环绕网孔：小区里的 “网格快递路线”

#### 场景类比：

小区是 “棋盘格” 布局（比如 1 栋 1 单元→1 栋 2 单元→1 栋 3 单元；2 栋 1 单元→2 栋 2 单元→2 栋 3 单元），而且 “最左边单元能直接连最右边，最上边单元能直接连最下边”（比如 1 栋 3 单元右边是 1 栋 1 单元，2 栋 3 单元下边是 1 栋 3 单元）—— 相当于把棋盘卷成了 “甜甜圈”，没有 “尽头”。现在两个快递站送货：

- 快递站 C（1 栋 1 单元）要给 2 栋 3 单元送；
- 快递站 D（2 栋 2 单元）要给 1 栋 2 单元送。

#### SF 多到多传输过程：

1. 快递站 C 送货

   按 “先横后竖” 的规则（先沿 “栋数” 方向，再沿 “单元数” 方向）：

   - 先把包裹完整交给 2 栋 1 单元（横方向），2 栋 1 单元 “收全确认” 后，再沿单元方向交给 2 栋 2 单元，2 栋 2 单元 “收全确认” 后，交给 2 栋 3 单元（目标）。

2. **快递站 D 送货**：
   目标 1 栋 2 单元离得近，直接沿 “栋数” 方向（2 栋→1 栋），把包裹交给 1 栋 2 单元，对方 “收全确认” 就完成（因为环绕特性，不用绕远路）。

#### 遇到 “堵车” 怎么办？

如果两条路线都要经过 2 栋 2 单元，2 栋的快递点会先收下一条路线的包裹，转发完再处理另一条，同时还能选 “绕路”（比如横方向走左边还是右边），减少碰面的概率。

#### 特点：

像走棋盘，能选的路线多，比环形快，适合小区（节点）数量中等的情况。

### 3. 超立方网络：小区里的 “多维快递路线”

#### 场景类比：

小区的快递路线是 “多维的”—— 每个楼的编号是二进制（比如 000 楼、001 楼、010 楼…111 楼），只要两个楼的编号 “只差一个数字”（比如 000 和 001、010、100），就能直接送快递，相当于每个楼有 “多个邻居楼”（比如 000 楼能直接连 3 个楼）。现在两个快递站送货：

- 快递站 E（000 楼）要给 011 楼送；
- 快递站 F（100 楼）要给 110 楼送。

#### SF 多到多传输过程：

1. **快递站 E 送货**：
   000 楼和 011 楼的编号差 “后两位”（0→1，0→1），先把包裹完整交给 001 楼（改最后一位），001 楼 “收全确认” 后，再交给 011 楼（改中间一位），目标收下完成。
2. **快递站 F 送货**：
   100 楼和 110 楼只差 “中间一位”（0→1），直接把包裹交给 110 楼，对方 “收全确认” 就完成，一步到位。

#### 遇到 “堵车” 怎么办？

因为每个楼能连多个邻居，大部分包裹的路线都不重合（比如 E 走 000→001→011，F 走 100→110），很少堵车。就算偶尔碰面，快递点也会先收全一个再转另一个，不影响。

#### 特点：

路线像 “立体网”，邻居多、路径短，送得最快，适合小区（节点）特别多的情况（比如超级大社区）。